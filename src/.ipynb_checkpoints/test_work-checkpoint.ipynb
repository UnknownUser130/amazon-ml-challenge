{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b70b34e",
   "metadata": {},
   "source": [
    "### Basic library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "719d15af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8911e33",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d3136aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = '../Projects/dataset/'\n",
    "train = pd.read_csv(os.path.join(DATASET_FOLDER, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATASET_FOLDER, 'test.csv'))\n",
    "\n",
    "#sample_test = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test.csv'))\n",
    "#sample_test_out = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test_out.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5a205ffd-7225-4f5b-b6d6-d9e21667a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'cm', 'foot', 'ft', 'inch', 'in', 'metre', 'm', 'millimetre', 'mm', 'yard', 'yd'},\n",
    "    'depth': {'centimetre', 'cm', 'foot', 'ft', 'inch', 'in', 'metre', 'm', 'millimetre', 'mm', 'yard', 'yd'},\n",
    "    'height': {'centimetre', 'cm', 'foot', 'ft', 'inch', 'in', 'metre', 'm', 'millimetre', 'mm', 'yard', 'yd'},\n",
    "    'item_weight': {\n",
    "        'gram', 'g', 'gm', \n",
    "        'kilogram', 'kg', \n",
    "        'microgram', 'µg', \n",
    "        'milligram', 'mg', \n",
    "        'ounce', 'oz', \n",
    "        'pound', 'lb', \n",
    "        'ton', 't'\n",
    "    },\n",
    "    'maximum_weight_recommendation': {\n",
    "        'gram', 'g', 'gm', \n",
    "        'kilogram', 'kg', \n",
    "        'microgram', 'µg', \n",
    "        'milligram', 'mg', \n",
    "        'ounce', 'oz', \n",
    "        'pound', 'lb', \n",
    "        'ton', 't'\n",
    "    },\n",
    "    'voltage': {'kilovolt', 'kV', 'millivolt', 'mV', 'volt', 'V'},\n",
    "    'wattage': {'kilowatt', 'kW', 'watt', 'W'},\n",
    "    'item_volume': {\n",
    "        'centilitre', 'cL', \n",
    "        'cubic foot', 'ft³', \n",
    "        'cubic inch', 'in³', \n",
    "        'cup', 'c', \n",
    "        'decilitre', 'dL', \n",
    "        'fluid ounce', 'fl oz', \n",
    "        'gallon', 'gal', \n",
    "        'imperial gallon', 'imp gal', \n",
    "        'litre', 'L', \n",
    "        'microlitre', 'µL', \n",
    "        'millilitre', 'mL', \n",
    "        'pint', 'pt', \n",
    "        'quart', 'qt'\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ebd689",
   "metadata": {},
   "source": [
    "### Run Sanity check using src/sanity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "81bb3988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Filepath: ../dataset/sample_test.csv invalid or not found.\n"
     ]
    }
   ],
   "source": [
    "!python sanity.py --test_filename ../dataset/sample_test.csv --output_filename ../dataset/sample_test_out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5aa79459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Filepath: ../dataset/sample_test.csv invalid or not found.\n"
     ]
    }
   ],
   "source": [
    "!python sanity.py --test_filename ../dataset/sample_test.csv --output_filename ../dataset/sample_test_out_fail.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe930a8",
   "metadata": {},
   "source": [
    "### Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a3d1aad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from utils import download_images\\ndownload_images(t['image_link'], '../images')\""
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from utils import download_images\n",
    "download_images(t['image_link'], '../images')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "89aaba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert len(os.listdir('../images')) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1ba3d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ../images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a7cc5e-40aa-4c1e-ba19-1b0a530f0cf4",
   "metadata": {},
   "source": [
    "## Mapping url to its file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9ad06-8584-41d2-82d8-925bcff0d076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "140743c9-3d3a-45b4-99b2-e52b66f98262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_link   image_filename\n",
      "0  https://m.media-amazon.com/images/I/61I9XdN6OF...  61I9XdN6OFL.jpg\n",
      "1  https://m.media-amazon.com/images/I/71gSRbyXmo...  71gSRbyXmoL.jpg\n",
      "2  https://m.media-amazon.com/images/I/61BZ4zrjZX...  61BZ4zrjZXL.jpg\n",
      "3  https://m.media-amazon.com/images/I/612mrlqiI4...  612mrlqiI4L.jpg\n",
      "4  https://m.media-amazon.com/images/I/617Tl40LOX...  617Tl40LOXL.jpg\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "train['image_filename'] = train['image_link'].apply(lambda x: os.path.basename(urlparse(x).path))\n",
    "\n",
    "# Display the dataframe to check the extracted filenames\n",
    "print(train[['image_link', 'image_filename']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "23d993bd-77a1-4615-aca0-4ab7fc6d3547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>image_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244003</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51zf4b8EGO...</td>\n",
       "      <td>521308</td>\n",
       "      <td>height</td>\n",
       "      <td>35.0 inch</td>\n",
       "      <td>51zf4b8EGOL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239233</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51tDiN7Cq7...</td>\n",
       "      <td>569206</td>\n",
       "      <td>height</td>\n",
       "      <td>5.0 centimetre</td>\n",
       "      <td>51tDiN7Cq7L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166431</th>\n",
       "      <td>https://m.media-amazon.com/images/I/41HdswhLQ-...</td>\n",
       "      <td>858439</td>\n",
       "      <td>width</td>\n",
       "      <td>9.8 centimetre</td>\n",
       "      <td>41HdswhLQ-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245044</th>\n",
       "      <td>https://m.media-amazon.com/images/I/614hd17CI9...</td>\n",
       "      <td>858439</td>\n",
       "      <td>height</td>\n",
       "      <td>29.0 centimetre</td>\n",
       "      <td>614hd17CI9L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12479</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71iWpPgI0G...</td>\n",
       "      <td>558374</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>100 gram</td>\n",
       "      <td>71iWpPgI0GL.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image_link  group_id  \\\n",
       "244003  https://m.media-amazon.com/images/I/51zf4b8EGO...    521308   \n",
       "239233  https://m.media-amazon.com/images/I/51tDiN7Cq7...    569206   \n",
       "166431  https://m.media-amazon.com/images/I/41HdswhLQ-...    858439   \n",
       "245044  https://m.media-amazon.com/images/I/614hd17CI9...    858439   \n",
       "12479   https://m.media-amazon.com/images/I/71iWpPgI0G...    558374   \n",
       "\n",
       "        entity_name     entity_value   image_filename  \n",
       "244003       height        35.0 inch  51zf4b8EGOL.jpg  \n",
       "239233       height   5.0 centimetre  51tDiN7Cq7L.jpg  \n",
       "166431        width   9.8 centimetre  41HdswhLQ-L.jpg  \n",
       "245044       height  29.0 centimetre  614hd17CI9L.jpg  \n",
       "12479   item_weight         100 gram  71iWpPgI0GL.jpg  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "35215873-b3c3-49b7-8dd2-ffc6b896693e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>image_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n",
       "      <td>748919</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>500.0 gram</td>\n",
       "      <td>61I9XdN6OFL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71gSRbyXmo...</td>\n",
       "      <td>916768</td>\n",
       "      <td>item_volume</td>\n",
       "      <td>1.0 cup</td>\n",
       "      <td>71gSRbyXmoL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61BZ4zrjZX...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>61BZ4zrjZXL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612mrlqiI4...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>612mrlqiI4L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/617Tl40LOX...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "      <td>617Tl40LOXL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263854</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612J1R1xHl...</td>\n",
       "      <td>558806</td>\n",
       "      <td>height</td>\n",
       "      <td>5.0 centimetre</td>\n",
       "      <td>612J1R1xHlL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263855</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61Blzh2+28...</td>\n",
       "      <td>470067</td>\n",
       "      <td>height</td>\n",
       "      <td>8.5 inch</td>\n",
       "      <td>61Blzh2+28L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263856</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51MsegDL9V...</td>\n",
       "      <td>204245</td>\n",
       "      <td>height</td>\n",
       "      <td>43.2 centimetre</td>\n",
       "      <td>51MsegDL9VL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263857</th>\n",
       "      <td>https://m.media-amazon.com/images/I/510KhVw4VS...</td>\n",
       "      <td>752266</td>\n",
       "      <td>height</td>\n",
       "      <td>9.1 centimetre</td>\n",
       "      <td>510KhVw4VSL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263858</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51lzTNLQ-6...</td>\n",
       "      <td>416664</td>\n",
       "      <td>height</td>\n",
       "      <td>27.5 centimetre</td>\n",
       "      <td>51lzTNLQ-6S.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255906 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image_link  group_id  \\\n",
       "0       https://m.media-amazon.com/images/I/61I9XdN6OF...    748919   \n",
       "1       https://m.media-amazon.com/images/I/71gSRbyXmo...    916768   \n",
       "2       https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516   \n",
       "3       https://m.media-amazon.com/images/I/612mrlqiI4...    459516   \n",
       "4       https://m.media-amazon.com/images/I/617Tl40LOX...    731432   \n",
       "...                                                   ...       ...   \n",
       "263854  https://m.media-amazon.com/images/I/612J1R1xHl...    558806   \n",
       "263855  https://m.media-amazon.com/images/I/61Blzh2+28...    470067   \n",
       "263856  https://m.media-amazon.com/images/I/51MsegDL9V...    204245   \n",
       "263857  https://m.media-amazon.com/images/I/510KhVw4VS...    752266   \n",
       "263858  https://m.media-amazon.com/images/I/51lzTNLQ-6...    416664   \n",
       "\n",
       "        entity_name     entity_value   image_filename  \n",
       "0       item_weight       500.0 gram  61I9XdN6OFL.jpg  \n",
       "1       item_volume          1.0 cup  71gSRbyXmoL.jpg  \n",
       "2       item_weight       0.709 gram  61BZ4zrjZXL.jpg  \n",
       "3       item_weight       0.709 gram  612mrlqiI4L.jpg  \n",
       "4       item_weight   1400 milligram  617Tl40LOXL.jpg  \n",
       "...             ...              ...              ...  \n",
       "263854       height   5.0 centimetre  612J1R1xHlL.jpg  \n",
       "263855       height         8.5 inch  61Blzh2+28L.jpg  \n",
       "263856       height  43.2 centimetre  51MsegDL9VL.jpg  \n",
       "263857       height   9.1 centimetre  510KhVw4VSL.jpg  \n",
       "263858       height  27.5 centimetre  51lzTNLQ-6S.jpg  \n",
       "\n",
       "[255906 rows x 5 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate rows based on the 'image_id' column\n",
    "train_cleaned = train.drop_duplicates(subset='image_filename', keep='first')\n",
    "\n",
    "trained_cleaned=train_cleaned.head(100)\n",
    "train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b0220a02-6802-4ae8-a7a5-3e936fa5b0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_link', 'group_id', 'entity_name', 'entity_value',\n",
       "       'image_filename'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "if train_cleaned['image_filename'].duplicated().any():\n",
    "    print(\"Warning: Duplicate image IDs found in CSV!\")\n",
    "train_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0896c515-ba7a-4cbc-8207-8f91372b7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import tensorflow as tf\n",
    "\n",
    "image_count = len(list(os.listdir('../Projects/images')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dcbb3bee-3d04-4b21-b253-3a9c8d683e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111723\n"
     ]
    }
   ],
   "source": [
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "15d9a4b9-6537-4fe7-846a-2cb6570a963a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport pandas as pd\\n\\n# Define the image directory path\\nimage_directory = \"../Projects/images/\"\\n\\nimage_files_in_dir = set(os.listdir(image_directory))\\n\\n# Filter the DataFrame to keep only rows where image_filename exists in the directory\\ntrain_cleaned_filtered = train_cleaned[train_cleaned[\\'image_filename\\'].isin(image_files_in_dir)]\\n\\nfor new_index, row in enumerate(train_cleaned_filtered.itertuples(), start=1):\\n    old_image_name = row.image_filename\\n    old_image_path = os.path.join(image_directory, old_image_name)\\n\\n    # Create the new image name\\n    new_image_name = f\"{new_index}.jpg\"\\n    new_image_path = os.path.join(image_directory, new_image_name)\\n\\n    # Rename the image file in the directory\\n    os.rename(old_image_path, new_image_path)\\n\\n    # Update the DataFrame with the new image filename\\n    train_cleaned_filtered.at[row.Index, \"image_filename\"] = new_image_name'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the image directory path\n",
    "image_directory = \"../Projects/images/\"\n",
    "\n",
    "image_files_in_dir = set(os.listdir(image_directory))\n",
    "\n",
    "# Filter the DataFrame to keep only rows where image_filename exists in the directory\n",
    "train_cleaned_filtered = train_cleaned[train_cleaned['image_filename'].isin(image_files_in_dir)]\n",
    "\n",
    "for new_index, row in enumerate(train_cleaned_filtered.itertuples(), start=1):\n",
    "    old_image_name = row.image_filename\n",
    "    old_image_path = os.path.join(image_directory, old_image_name)\n",
    "\n",
    "    # Create the new image name\n",
    "    new_image_name = f\"{new_index}.jpg\"\n",
    "    new_image_path = os.path.join(image_directory, new_image_name)\n",
    "\n",
    "    # Rename the image file in the directory\n",
    "    os.rename(old_image_path, new_image_path)\n",
    "\n",
    "    # Update the DataFrame with the new image filename\n",
    "    train_cleaned_filtered.at[row.Index, \"image_filename\"] = new_image_name'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e10c774d-60e6-4c32-8cc2-9bd4204f269b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Save the filtered DataFrame if needed\\ntrain_cleaned_filtered.to_csv(\\'filtered_dataframe.csv\\', index=False)\\n\\n\\nprint(\"Filtering completed. Remaining rows:\", len(train_cleaned_filtered))\\ntrain_cleaned_filtered'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Save the filtered DataFrame if needed\n",
    "train_cleaned_filtered.to_csv('filtered_dataframe.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"Filtering completed. Remaining rows:\", len(train_cleaned_filtered))\n",
    "train_cleaned_filtered'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d9e3a162-93c8-41ca-8fc4-bbfef8e6b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv( 'filtered_dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e20727-4e0b-4360-9714-4b60a86184ba",
   "metadata": {},
   "source": [
    "## For out of memory errors in GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "491400cf-6358-4b6c-a227-4769c5f1db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# List all physical devices and set memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91aaa5e-9602-4e53-86b4-efc96a9e5777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ca4307d-32e6-49b7-914d-9e15412d9d68",
   "metadata": {},
   "source": [
    "##IMAGE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c1572fba-0c9b-47e0-be09-8218c6be93fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image, ImageEnhance\n",
    "import tensorflow as tf\n",
    "\n",
    "class CustomImageDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, image_paths, batch_size, image_size, contrast_factor=1.1):\n",
    "        self.image_paths = image_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.contrast_factor = contrast_factor\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        # Convert to grayscale\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Denoise using Non-Local Means Denoising\n",
    "        denoised_image = cv2.fastNlMeansDenoising(gray_image, None, 5, 7, 21)\n",
    "        \n",
    "        # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) for better contrast\n",
    "        clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(16, 16))\n",
    "        enhanced_contrast = clahe.apply(denoised_image)\n",
    "        \n",
    "        # Adaptive thresholding for better binary conversion in uneven lighting\n",
    "        binary_image = cv2.adaptiveThreshold(enhanced_contrast, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                             cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        # Optional: Apply morphological operations to clean up small noise\n",
    "        kernel = np.ones((1, 1), np.uint8)\n",
    "        morphed_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Convert to PIL Image\n",
    "        pil_image = Image.fromarray(morphed_image)\n",
    "        \n",
    "        # Enhance contrast using PIL for fine-tuning\n",
    "        enhancer = ImageEnhance.Contrast(pil_image)\n",
    "        enhanced_image = enhancer.enhance(self.contrast_factor)\n",
    "        \n",
    "        return np.array(enhanced_image)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_paths = self.image_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_images = []\n",
    "        \n",
    "        for path in batch_paths:\n",
    "            try:\n",
    "                image = cv2.imread(path)\n",
    "                if image is None:\n",
    "                    print(f\"Warning: Unable to load image {path}\")\n",
    "                    continue\n",
    "                image = cv2.resize(image, self.image_size)  # Resize image\n",
    "                image = self.preprocess_image(image)  # Apply the preprocessing pipeline\n",
    "                \n",
    "                # Append to batch_images\n",
    "                batch_images.append(image)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {path}: {e}\")\n",
    "        \n",
    "        batch_images = np.array(batch_images)\n",
    "        return batch_images\n",
    "batch_size = 100\n",
    "image_size = (1536, 1536)  # Set image size to 1024x1024\n",
    "data_generator = CustomImageDataGenerator(image_paths, batch_size=batch_size, image_size=image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b6598-df18-44e1-9851-c48af45a5a0a",
   "metadata": {},
   "source": [
    "## Splitting entity_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8eacd93f-107d-4a3d-9be9-caaef506051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from PIL import Image  # Ensure PIL is imported for image processing\n",
    "import os\n",
    "\n",
    "# Define the unit extraction map\n",
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'cm', 'foot', 'ft', 'inch', 'in', 'metre', 'm', 'millimetre', 'mm', 'yard', 'yd'},\n",
    "    'depth': {'centimetre', 'cm', 'foot', 'ft', 'inch', 'in', 'metre', 'm', 'millimetre', 'mm', 'yard', 'yd'},\n",
    "    'height': {'centimetre', 'cm', 'foot', 'ft', 'inch', 'in', 'metre', 'm', 'millimetre', 'mm', 'yard', 'yd'},\n",
    "    'item_weight': {'gram', 'g', 'gm', 'kilogram', 'kg', 'microgram', 'µg', 'milligram', 'mg', 'ounce', 'oz', 'pound', 'lb', 'ton', 't'},\n",
    "    'maximum_weight_recommendation': {'gram', 'g', 'gm', 'kilogram', 'kg', 'microgram', 'µg', 'milligram', 'mg', 'ounce', 'oz', 'pound', 'lb', 'ton', 't'},\n",
    "    'voltage': {'kilovolt', 'kV', 'millivolt', 'mV', 'volt', 'V'},\n",
    "    'wattage': {'kilowatt', 'kW', 'watt', 'W'},\n",
    "    'item_volume': {'centilitre', 'cL', 'cubic foot', 'ft³', 'cubic inch', 'in³', 'cup', 'c', 'decilitre', 'dL', 'fluid ounce', 'fl oz', 'gallon', 'gal', 'imperial gallon', 'imp gal', 'litre', 'L', 'microlitre', 'µL', 'millilitre', 'mL', 'pint', 'pt', 'quart', 'qt'}\n",
    "}\n",
    "\n",
    "def extract_value_and_unit(text, allowed_units):\n",
    "    value = None\n",
    "    unit = None\n",
    "    value_pattern = re.compile(r'\\d+(\\.\\d+)?')\n",
    "    unit_pattern = re.compile(r'\\b(?:' + '|'.join(re.escape(unit) for unit in allowed_units) + r')\\b', re.IGNORECASE)\n",
    "    value_match = value_pattern.search(text)\n",
    "    unit_match = unit_pattern.search(text)\n",
    "    if value_match:\n",
    "        value = value_match.group()\n",
    "    if unit_match:\n",
    "        unit = unit_match.group()\n",
    "    return value, unit\n",
    "\n",
    "def extract_entities_from_image(image, image_filename):\n",
    "    # Convert NumPy image to PIL format (if needed for pytesseract)\n",
    "    pil_image = Image.fromarray(image)\n",
    "\n",
    "    # Perform OCR\n",
    "    text = pytesseract.image_to_string(pil_image, output_type=Output.STRING)\n",
    "    \n",
    "    extracted_values = []\n",
    "    for entity, units in entity_unit_map.items():\n",
    "        value, unit = extract_value_and_unit(text, units)\n",
    "        if value and unit:\n",
    "            extracted_values.append(f'{value} {unit}')\n",
    "    \n",
    "    # Print the extracted values for debugging\n",
    "    print(f'Extracted from {image_filename}: {\", \".join(extracted_values)}')\n",
    "\n",
    "    return {\n",
    "        'image_filename': image_filename,\n",
    "        'Text': ', '.join(extracted_values)  # Combine all extracted values into a single string\n",
    "    }\n",
    "\n",
    "def process_batch(images, filenames):\n",
    "    data = []\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = executor.map(lambda image_file: extract_entities_from_image(*image_file), zip(images, filenames))\n",
    "        for result in results:\n",
    "            data.append(result)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22947de1-aeec-4b40-9529-4af17b87b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batches(data_generator, train_cleaned_filtered, batch_size=64, num_batches=None):\n",
    "    \"\"\"\n",
    "    Process a specified number of batches of preprocessed images.\n",
    "\n",
    "    Parameters:\n",
    "    - data_generator: Generator that yields preprocessed images.\n",
    "    - train_cleaned_filtered: DataFrame with image filenames and other data.\n",
    "    - batch_size: Number of images per batch (default: 64).\n",
    "    - num_batches: Number of batches to process (None means process all batches).\n",
    "    \"\"\"\n",
    "    total_batches = len(data_generator) if num_batches is None else min(num_batches, len(data_generator))\n",
    "\n",
    "    for i in range(total_batches):\n",
    "        batch_images = data_generator[i]  # Get preprocessed images for this batch\n",
    "        batch_filenames = data_generator.image_paths[i * batch_size:(i + 1) * batch_size]  # Corresponding filenames\n",
    "        \n",
    "        # Filter filenames that are present in the dataset (consistent dataframe usage)\n",
    "        matching_filenames = [filename for filename in batch_filenames if os.path.basename(filename) in train_cleaned_filtered['image_filename'].values]\n",
    "        matching_images = [image for image, filename in zip(batch_images, batch_filenames) if os.path.basename(filename) in train_cleaned_filtered['image_filename'].values]\n",
    "        \n",
    "        # Check for empty batches\n",
    "        if len(matching_images) == 0:\n",
    "            print(f\"No matching images found for batch {i + 1}\")\n",
    "            continue\n",
    "        \n",
    "        # Extract text from the batch of matching images\n",
    "        new_data = process_batch(matching_images, [os.path.basename(path) for path in matching_filenames])\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "\n",
    "        # Update train_cleaned_filtered based on new_df\n",
    "        for _, row in new_df.iterrows():\n",
    "            image_filename = row['image_filename']\n",
    "            text = row['Text']\n",
    "\n",
    "            # Update the 'Text' field for matching image filenames\n",
    "            if image_filename in train_cleaned_filtered['image_filename'].values:\n",
    "                train_cleaned_filtered.loc[train_cleaned_filtered['image_filename'] == image_filename, 'Text'] = text\n",
    "\n",
    "        print(f'Processed batch {i + 1}')\n",
    "        \n",
    "        # Save the updated dataframe after each batch\n",
    "        train_cleaned_filtered.to_csv('updated_train_cleaned_filtered.csv', index=False)  # Save after each batch\n",
    "\n",
    "# Example usage\n",
    "num_batches_to_process = 5  # Change this to the number of batches you want to process\n",
    "process_batches(data_generator, train_cleaned_filtered, batch_size=100, num_batches=num_batches_to_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca0554-6e2b-40ff-8425-37a3e1040327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5405e3-20f1-4a41-8c62-cb24fa35bd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf960a8c-6490-496c-9513-1d4eaedd1bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
